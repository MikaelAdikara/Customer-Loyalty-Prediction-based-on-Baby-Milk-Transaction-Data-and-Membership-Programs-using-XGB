{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97c8b564",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rapha\\Documents\\VSCode\\Kaggle\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# 1. Imports and Configurations\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from collections import Counter\n",
    "from itertools import combinations\n",
    "\n",
    "# Preprocessing & Feature Engineering\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif, RFE\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# Imbalance Handling\n",
    "from imblearn.over_sampling import SMOTE, ADASYN, BorderlineSMOTE\n",
    "from imblearn.combine import SMOTEENN, SMOTETomek\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "\n",
    "# Models & Tuning\n",
    "import lightgbm as lgb\n",
    "import optuna\n",
    "import shap\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import (\n",
    "    f1_score, roc_auc_score, roc_curve, precision_recall_curve, confusion_matrix,\n",
    "    precision_score, recall_score, accuracy_score\n",
    ")\n",
    "\n",
    "# Configurations and Style\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"mako\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762bfb31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading data...\")\n",
    "train_df = pd.read_csv(r'C:\\Users\\rapha\\Documents\\VSCode\\Kaggle\\Intellectra\\Datasets\\Processed (2)\\Datasetstrain_improved.csv')\n",
    "test_df = pd.read_csv(r'C:\\Users\\rapha\\Documents\\VSCode\\Kaggle\\Intellectra\\Datasets\\Processed (2)\\Datasetstest_improved.csv')\n",
    "\n",
    "N_SPLITS = 5\n",
    "RANDOM_STATE = 42\n",
    "OPTUNA_TRIALS = 50  # adjust for runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99804446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering\n",
    "print(\"\\n2. Creating advanced features...\")\n",
    "# --- Feature Engineering ---\n",
    "def create_advanced_features(df):\n",
    "    \"\"\"Create advanced features for better model performance.\"\"\"\n",
    "    df = df.copy()\n",
    "    # Behavioral Patterns\n",
    "    df['transaction_momentum'] = df['total_transactions'] / (df['recency_days'] + 1)\n",
    "    df['spending_acceleration'] = df['total_spent'] / (df['customer_lifetime_days'] + 1)\n",
    "    df['value_consistency'] = df['avg_transaction_value'] / (df['transaction_value_std'].fillna(0) + 1)\n",
    "    \n",
    "    # Engagement Metrics\n",
    "    df['days_since_last_purchase'] = df['recency_days']\n",
    "    df['purchase_intensity'] = df['total_transactions'] / (df['membership_tenure_days'] + 1)\n",
    "    df['loyalty_ratio'] = df['customer_lifetime_days'] / (df['membership_tenure_days'] + 1)\n",
    "    \n",
    "    # Customer Lifecycle Features\n",
    "    df['is_new_customer'] = (df['membership_tenure_days'] < 30).astype(int)\n",
    "    df['is_dormant'] = (df['recency_days'] > 90).astype(int)\n",
    "    df['is_high_value'] = (df['total_spent'] > df['total_spent'].quantile(0.8)).astype(int)\n",
    "    \n",
    "    # Temporal Features\n",
    "    df['avg_monthly_transactions'] = df['total_transactions'] / ((df['customer_lifetime_days'] / 30) + 1)\n",
    "    df['avg_monthly_spend'] = df['total_spent'] / ((df['customer_lifetime_days'] / 30) + 1)\n",
    "    \n",
    "    # Diversity Features\n",
    "    df['product_exploration'] = df['unique_products'] / (df['total_transactions'] + 1)\n",
    "    df['channel_diversity'] = df['unique_sources'] / (df['total_transactions'] + 1)\n",
    "    \n",
    "    # Family-based Features\n",
    "    if all(col in df.columns for col in ['has_children', 'NoOfChild', 'eldest_child_age', 'youngest_child_age']):\n",
    "        df['child_factor'] = df['has_children'] * (df['eldest_child_age'].fillna(0) + df['youngest_child_age'].fillna(0)) / 2\n",
    "        df['family_spending_per_child'] = df['total_spent'] / (df['NoOfChild'] + 1)\n",
    "    elif 'NoOfChild' in df.columns:\n",
    "        df['family_spending_per_child'] = df['total_spent'] / (df['NoOfChild'] + 1)\n",
    "    \n",
    "    # Interaction Features\n",
    "    if all(col in df.columns for col in ['recency_score', 'frequency_score', 'monetary_score']):\n",
    "        df['rfm_interaction'] = df['recency_score'] * df['frequency_score'] * df['monetary_score']\n",
    "    \n",
    "    if all(col in df.columns for col in ['avg_transaction_value', 'total_transactions', 'customer_lifetime_days']):\n",
    "        df['transaction_frequency'] = df['total_transactions'] / (df['customer_lifetime_days'] + 1) * 30\n",
    "        df['value_frequency_ratio'] = df['avg_transaction_value'] * df['transaction_frequency']\n",
    "\n",
    "    return df\n",
    "train_df = create_advanced_features(train_df)\n",
    "test_df = create_advanced_features(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6debe754",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "print(\"\\n3. Preprocessing data for modeling...\")\n",
    "def create_target_encoding_features(df_train, df_test, categorical_cols, target_col):\n",
    "    \"\"\"Create target encoding features with cross-validation.\"\"\"\n",
    "    df_train_out = df_train.copy()\n",
    "    df_test_out = df_test.copy()\n",
    "    \n",
    "    kf = KFold(n_splits=N_SPLITS, shuffle=True, random_state=RANDOM_STATE)\n",
    "    \n",
    "    for col in categorical_cols:\n",
    "        if col in df_train_out.columns:\n",
    "            df_train_out[f'{col}_target_enc'] = 0\n",
    "            for train_idx, val_idx in kf.split(df_train_out):\n",
    "                train_fold, val_fold = df_train_out.iloc[train_idx], df_train_out.iloc[val_idx]\n",
    "                target_mean = train_fold.groupby(col)[target_col].mean()\n",
    "                df_train_out.loc[val_idx, f'{col}_target_enc'] = val_fold[col].map(target_mean).fillna(target_mean.mean())\n",
    "            \n",
    "            full_train_mean = df_train_out.groupby(col)[target_col].mean()\n",
    "            df_test_out[f'{col}_target_enc'] = df_test_out[col].map(full_train_mean).fillna(full_train_mean.mean())\n",
    "    \n",
    "    return df_train_out, df_test_out\n",
    "\n",
    "# --- Data Preprocessing ---\n",
    "def preprocess_for_modeling(df_train, df_test):\n",
    "    \"\"\"Prepares train and test dataframes for modeling.\"\"\"\n",
    "    X = df_train.drop('next_buy', axis=1)\n",
    "    y = df_train['next_buy']\n",
    "    X_test = df_test.copy()\n",
    "\n",
    "    categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "    \n",
    "    cols_to_drop = [\n",
    "        'MemberID', 'first_transaction', 'last_transaction', 'JoinDate',\n",
    "        'EldestKidDOB', 'YoungestKidDOB', 'City', 'preferred_source',\n",
    "        'preferred_source_grouped'\n",
    "    ]\n",
    "    X.drop(columns=cols_to_drop, errors='ignore', inplace=True)\n",
    "    X_test.drop(columns=cols_to_drop, errors='ignore', inplace=True)\n",
    "\n",
    "    categorical_cols = [c for c in categorical_cols if c not in cols_to_drop]\n",
    "\n",
    "    X_temp = X.copy()\n",
    "    X_temp['next_buy'] = y\n",
    "    X_temp, X_test = create_target_encoding_features(X_temp, X_test, categorical_cols, 'next_buy')\n",
    "    X = X_temp.drop('next_buy', axis=1)\n",
    "\n",
    "    remaining_categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "    X = pd.get_dummies(X, columns=remaining_categorical_cols, dummy_na=True, drop_first=True)\n",
    "    X_test = pd.get_dummies(X_test, columns=remaining_categorical_cols, dummy_na=True, drop_first=True)\n",
    "\n",
    "    X, X_test = X.align(X_test, join='left', axis=1, fill_value=0)\n",
    "    \n",
    "    # Ensure test set has all columns from train set after alignment\n",
    "    for col in X.columns:\n",
    "        if col not in X_test.columns:\n",
    "             X_test[col] = 0\n",
    "    X_test = X_test[X.columns] # Ensure same column order\n",
    "\n",
    "    print(f\"Data preprocessed. Number of features: {X.shape[1]}\")\n",
    "    return X, y, X_test\n",
    "\n",
    "X, y, X_test = preprocess_for_modeling(train_df, test_df)\n",
    "# Handle infinite values that may result from feature engineering\n",
    "X.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "X_test.replace([np.inf, -np.inf], np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3725678",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Exploratory Analysis\n",
    "print(\"\\n4. Running exploratory analysis...\")\n",
    "# --- Analysis & Exploration Functions ---\n",
    "def compare_sampling_strategies(X, y):\n",
    "    \"\"\"Compare different sampling strategies.\"\"\"\n",
    "    print(\"\\nOriginal class distribution:\", Counter(y))\n",
    "    sampling_strategies = {\n",
    "        'SMOTE': SMOTE(random_state=RANDOM_STATE),\n",
    "        'ADASYN': ADASYN(random_state=RANDOM_STATE),\n",
    "        'BorderlineSMOTE': BorderlineSMOTE(random_state=RANDOM_STATE),\n",
    "        'SMOTEENN': SMOTEENN(random_state=RANDOM_STATE),\n",
    "        'SMOTETomek': SMOTETomek(random_state=RANDOM_STATE)\n",
    "    }\n",
    "    results = {}\n",
    "    imputer = SimpleImputer(strategy='median')\n",
    "    X_imputed = imputer.fit_transform(X)\n",
    "    \n",
    "    for name, sampler in sampling_strategies.items():\n",
    "        try:\n",
    "            X_resampled, y_resampled = sampler.fit_resample(X_imputed, y)\n",
    "            results[name] = {'X_shape': X_resampled.shape, 'class_distribution': Counter(y_resampled)}\n",
    "            print(f\"{name}: {Counter(y_resampled)}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error with {name}: {e}\")\n",
    "    return results\n",
    "\n",
    "def custom_cost_sensitive_learning(y):\n",
    "    \"\"\"Implement cost-sensitive learning approach.\"\"\"\n",
    "    class_counts = Counter(y)\n",
    "    total_samples = len(y)\n",
    "    weight_for_0 = total_samples / (2 * class_counts[0])\n",
    "    weight_for_1 = total_samples / (2 * class_counts[1]) * 2\n",
    "    class_weights = {0: weight_for_0, 1: weight_for_1}\n",
    "    print(f\"Custom class weights: {class_weights}\")\n",
    "    return class_weights\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "y.value_counts().plot(kind='pie', autopct='%1.1f%%', colors=sns.color_palette('viridis', 2))\n",
    "plt.title('Original Class Distribution')\n",
    "plt.ylabel('')\n",
    "plt.show()\n",
    "\n",
    "sampling_results = compare_sampling_strategies(X, y)\n",
    "custom_weights = custom_cost_sensitive_learning(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13885d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter Tuning\n",
    "print(f\"\\n5. Optimizing LightGBM hyperparameters with Optuna ({OPTUNA_TRIALS} trials)...\")\n",
    "# --- Modeling & Tuning ---\n",
    "def optimize_lightgbm(X, y, n_trials=10):\n",
    "    \"\"\"Optimize LightGBM hyperparameters using Optuna.\"\"\"\n",
    "    def objective(trial):\n",
    "        params = {\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "            'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "            'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "            'reg_alpha': trial.suggest_float('reg_alpha', 0, 10),\n",
    "            'reg_lambda': trial.suggest_float('reg_lambda', 0, 10),\n",
    "            'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
    "            'random_state': RANDOM_STATE,\n",
    "            'class_weight': 'balanced'\n",
    "        }\n",
    "        pipeline = ImbPipeline([\n",
    "            ('imputer', SimpleImputer(strategy='median')),\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('smote', SMOTE(random_state=RANDOM_STATE)),\n",
    "            ('classifier', lgb.LGBMClassifier(**params))\n",
    "        ])\n",
    "        \n",
    "        skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=RANDOM_STATE)\n",
    "        scores = []\n",
    "        for train_idx, val_idx in skf.split(X, y):\n",
    "            X_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n",
    "            X_val, y_val = X.iloc[val_idx], y.iloc[val_idx]\n",
    "            \n",
    "            pipeline.fit(X_train, y_train)\n",
    "            y_pred = pipeline.predict_proba(X_val)[:, 1]\n",
    "            score = roc_auc_score(y_val, y_pred)\n",
    "            scores.append(score)\n",
    "        \n",
    "        return np.mean(scores)\n",
    "    \n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(objective, n_trials=n_trials, n_jobs=-1)\n",
    "    return study.best_params\n",
    "best_lgbm_params = optimize_lightgbm(X, y, n_trials=OPTUNA_TRIALS)\n",
    "print(f\"Best LightGBM parameters found: {best_lgbm_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a342f338",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Model Training and Prediction\n",
    "print(\"\\n6. Training model with Stratified K-Fold cross-validation...\")\n",
    "def train_and_predict(X, y, X_test, lgbm_params):\n",
    "    \"\"\"Train the model using Stratified Cross-Validation and make predictions.\"\"\"\n",
    "    pipeline = ImbPipeline([\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('smote', SMOTE(random_state=RANDOM_STATE)),\n",
    "        ('classifier', lgb.LGBMClassifier(**lgbm_params))\n",
    "    ])\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=RANDOM_STATE)\n",
    "    \n",
    "    oof_preds = np.zeros(len(X))\n",
    "    test_preds = np.zeros(len(X_test))\n",
    "    feature_importances = pd.DataFrame(index=X.columns)\n",
    "    metrics = {'f1': [], 'roc_auc': [], 'precision': [], 'recall': [], 'accuracy': []}\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(X, y), 1):\n",
    "        print(f\"--- Fold {fold}/{N_SPLITS} ---\")\n",
    "        X_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n",
    "        X_val, y_val = X.iloc[val_idx], y.iloc[val_idx]\n",
    "\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        val_proba = pipeline.predict_proba(X_val)[:, 1]\n",
    "        val_class = pipeline.predict(X_val)\n",
    "\n",
    "        oof_preds[val_idx] = val_proba\n",
    "        test_preds += pipeline.predict_proba(X_test)[:, 1] / N_SPLITS\n",
    "        feature_importances[f'fold_{fold}'] = pipeline.named_steps['classifier'].feature_importances_\n",
    "\n",
    "        metrics['f1'].append(f1_score(y_val, val_class))\n",
    "        metrics['roc_auc'].append(roc_auc_score(y_val, val_proba))\n",
    "        metrics['precision'].append(precision_score(y_val, val_class))\n",
    "        metrics['recall'].append(recall_score(y_val, val_class))\n",
    "        metrics['accuracy'].append(accuracy_score(y_val, val_class))\n",
    "\n",
    "        print(f\"Validation F1-Score: {metrics['f1'][-1]:.4f}\")\n",
    "        print(f\"Validation ROC AUC: {metrics['roc_auc'][-1]:.4f}\\n\")\n",
    "    \n",
    "    print(\"--- Cross-Validation Summary ---\")\n",
    "    for name, vals in metrics.items():\n",
    "        print(f\"Average {name.upper()}: {np.mean(vals):.4f} (Std: {np.std(vals):.4f})\")\n",
    "        \n",
    "    return oof_preds, test_preds, feature_importances, pipeline\n",
    "oof_preds, test_preds, feature_importances, final_pipeline = train_and_predict(X, y, X_test, best_lgbm_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3859d1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "print(\"\\n7. Evaluating model performance...\")\n",
    "# --- Evaluation & Analysis ---\n",
    "def plot_evaluation_results(y_true, oof_preds, best_thresh):\n",
    "    \"\"\"Plot ROC, Precision-Recall curves and Confusion Matrix.\"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    # ROC Curve\n",
    "    fpr, tpr, _ = roc_curve(y_true, oof_preds)\n",
    "    ax1.plot(fpr, tpr, label=f\"AUC = {roc_auc_score(y_true, oof_preds):.4f}\")\n",
    "    ax1.plot([0, 1], [0, 1], 'k--')\n",
    "    ax1.set(title='ROC Curve (OOF)', xlabel='False Positive Rate', ylabel='True Positive Rate')\n",
    "    ax1.legend()\n",
    "    \n",
    "    # Precision-Recall Curve\n",
    "    precision, recall, _ = precision_recall_curve(y_true, oof_preds)\n",
    "    ax2.plot(recall, precision, label='PR Curve')\n",
    "    ax2.set(title='Precision-Recall Curve', xlabel='Recall', ylabel='Precision')\n",
    "    ax2.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(y_true, (oof_preds > best_thresh).astype(int))\n",
    "    plt.figure(figsize=(7, 5))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=['No Buy','Buy'], yticklabels=['No Buy','Buy'])\n",
    "    plt.title(f'Confusion Matrix (OOF) at Threshold {best_thresh:.2f}')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.show()\n",
    "    \n",
    "def advanced_threshold_optimization(y_true, y_proba):\n",
    "    \"\"\"Find optimal threshold considering business metrics.\"\"\"\n",
    "    thresholds = np.arange(0.1, 0.9, 0.01)\n",
    "    metrics = []\n",
    "    for threshold in thresholds:\n",
    "        y_pred = (y_proba > threshold).astype(int)\n",
    "        f1 = f1_score(y_true, y_pred)\n",
    "        precision = precision_score(y_true, y_pred)\n",
    "        recall = recall_score(y_true, y_pred)\n",
    "        business_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        metrics.append({'threshold': threshold, 'f1': f1, 'precision': precision, 'recall': recall, 'business_score': business_score})\n",
    "    \n",
    "    metrics_df = pd.DataFrame(metrics)\n",
    "    best_threshold = metrics_df.loc[metrics_df['business_score'].idxmax(), 'threshold']\n",
    "    print(f\"Optimal threshold based on business score: {best_threshold:.2f}\")\n",
    "    return best_threshold, metrics_df\n",
    "\n",
    "def plot_feature_importance(feature_importances_df):\n",
    "    \"\"\"Plot top 20 feature importances.\"\"\"\n",
    "    feature_importances_df['mean'] = feature_importances_df.mean(axis=1)\n",
    "    top_feats = feature_importances_df['mean'].nlargest(20)\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    sns.barplot(x=top_feats.values, y=top_feats.index)\n",
    "    plt.title('Top 20 Feature Importances (LGBM)')\n",
    "    plt.xlabel('Average Importance')\n",
    "    plt.ylabel('Feature')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "best_threshold, _ = advanced_threshold_optimization(y, oof_preds)\n",
    "plot_evaluation_results(y, oof_preds, best_threshold)\n",
    "plot_feature_importance(feature_importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea525986",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Advanced Analysis\n",
    "print(\"\\n8. Performing advanced feature analysis...\")\n",
    "def advanced_feature_selection(X, y, model, k_best=50):\n",
    "    \"\"\"Perform comprehensive feature selection.\"\"\"\n",
    "    imputer = SimpleImputer(strategy='median')\n",
    "    X_imputed = imputer.fit_transform(X)\n",
    "    \n",
    "    selector_f = SelectKBest(score_func=f_classif, k=min(k_best, X.shape[1])).fit(X_imputed, y)\n",
    "    f_test_features = X.columns[selector_f.get_support()].tolist()\n",
    "\n",
    "    selector_mi = SelectKBest(score_func=mutual_info_classif, k=min(k_best, X.shape[1])).fit(X_imputed, y)\n",
    "    mi_features = X.columns[selector_mi.get_support()].tolist()\n",
    "\n",
    "    rfe = RFE(estimator=model, n_features_to_select=min(k_best, X.shape[1]), step=1).fit(X_imputed, y)\n",
    "    rfe_features = X.columns[rfe.support_].tolist()\n",
    "    \n",
    "    model.fit(X_imputed, y)\n",
    "    perm_importance = permutation_importance(model, X_imputed, y, n_repeats=5, random_state=RANDOM_STATE, n_jobs=-1)\n",
    "    importance_df = pd.DataFrame({'feature': X.columns, 'importance': perm_importance.importances_mean}).sort_values('importance', ascending=False)\n",
    "    perm_features = importance_df.head(k_best)['feature'].tolist()\n",
    "    \n",
    "    feature_scores = {f: sum([f in s for s in [f_test_features, mi_features, rfe_features, perm_features]]) for f in X.columns}\n",
    "    selected_features = [f for f, score in feature_scores.items() if score >= 2]\n",
    "    \n",
    "    print(f\"Selected {len(selected_features)} features out of {len(X.columns)}\")\n",
    "    return selected_features, feature_scores\n",
    "    \n",
    "def explain_model_predictions(pipeline, X, y):\n",
    "    \"\"\"Generate SHAP explanations for model predictions.\"\"\"\n",
    "    imputer = pipeline.named_steps['imputer']\n",
    "    scaler = pipeline.named_steps['scaler']\n",
    "    classifier = pipeline.named_steps['classifier']\n",
    "    \n",
    "    # We fit the pipeline on the training data for SHAP\n",
    "    pipeline.fit(X, y)\n",
    "    \n",
    "    X_transformed = scaler.transform(imputer.transform(X))\n",
    "    X_transformed_df = pd.DataFrame(X_transformed, columns=X.columns)\n",
    "\n",
    "    explainer = shap.TreeExplainer(classifier)\n",
    "    shap_values = explainer.shap_values(X_transformed_df.sample(1000, random_state=RANDOM_STATE))\n",
    "\n",
    "    # For multi-class (even if binary), shap_values can be a list\n",
    "    plot_values = shap_values[1] if isinstance(shap_values, list) else shap_values\n",
    "\n",
    "    shap.summary_plot(plot_values, X_transformed_df.sample(1000, random_state=RANDOM_STATE), show=False)\n",
    "    plt.title('SHAP Feature Importance')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    avg_abs_shap = np.abs(plot_values).mean(0)\n",
    "    feature_importance = pd.DataFrame({'feature': X.columns, 'importance': avg_abs_shap}).sort_values('importance', ascending=False)\n",
    "    return feature_importance\n",
    "\n",
    "def detect_feature_interactions(X, y, top_n=10):\n",
    "    \"\"\"Detect important feature interactions.\"\"\"\n",
    "    imputer = SimpleImputer(strategy='median')\n",
    "    X_imputed = imputer.fit_transform(X)\n",
    "    \n",
    "    selector = SelectKBest(score_func=f_classif, k=min(20, X.shape[1])).fit(X_imputed, y)\n",
    "    top_features = X.columns[selector.get_support()].tolist()\n",
    "    \n",
    "    interaction_scores = []\n",
    "    for feat1, feat2 in combinations(top_features, 2):\n",
    "        interaction_term = (X[feat1] * X[feat2]).values.reshape(-1, 1)\n",
    "        interaction_filled = imputer.fit_transform(interaction_term).ravel()\n",
    "        score = mutual_info_classif(interaction_filled.reshape(-1, 1), y)[0]\n",
    "        interaction_scores.append({'feature1': feat1, 'feature2': feat2, 'interaction_score': score})\n",
    "    \n",
    "    interaction_df = pd.DataFrame(interaction_scores).sort_values('interaction_score', ascending=False)\n",
    "    return interaction_df.head(top_n)\n",
    "selected_features, _ = advanced_feature_selection(X, y, final_pipeline.named_steps['classifier'])\n",
    "\n",
    "print(f\"\\nTop features from composite selection: {selected_features[:15]}...\")\n",
    "    \n",
    "shap_importance = explain_model_predictions(final_pipeline, X, y)\n",
    "print(\"\\nTop SHAP Feature Importance:\\n\", shap_importance.head())\n",
    "    \n",
    "top_interactions = detect_feature_interactions(X, y)\n",
    "print(\"\\nTop feature interactions:\\n\", top_interactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8817d317",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submission File Generation\n",
    "print(\"\\n9. Generating submission file...\")\n",
    "# --- Submission Generation ---\n",
    "def generate_submission(test_df, test_preds, y, submission_path):\n",
    "    \"\"\"Generate and save the submission file with an adjusted threshold.\"\"\"\n",
    "    original_positive_proportion = y.value_counts(normalize=True).get(1, 0)\n",
    "    print(f\"Original training positive class proportion: {original_positive_proportion:.4f}\")\n",
    "\n",
    "    sorted_test_preds = np.sort(test_preds)[::-1]\n",
    "    desired_count_of_ones = int(len(test_preds) * original_positive_proportion)\n",
    "    \n",
    "    if desired_count_of_ones >= len(sorted_test_preds):\n",
    "        threshold_for_imbalance = sorted_test_preds[-1]\n",
    "    else:\n",
    "        threshold_for_imbalance = sorted_test_preds[desired_count_of_ones]\n",
    "\n",
    "    print(f\"Calculated threshold to match original imbalance: {threshold_for_imbalance:.4f}\")\n",
    "\n",
    "    submission = pd.DataFrame({\n",
    "        'MemberID': test_df['MemberID'],\n",
    "        'next_buy_probability': test_preds\n",
    "    })\n",
    "    submission['next_buy'] = (submission['next_buy_probability'] > threshold_for_imbalance).astype(int)\n",
    "    \n",
    "    submission_file = f'{submission_path}/submission.csv'\n",
    "    submission[['MemberID', 'next_buy']].to_csv(submission_file, index=False)\n",
    "    print(f\"Submission file created at: {submission_file}\")\n",
    "    print(submission.head())\n",
    "\n",
    "    print(\"\\nSubmission unique values distribution (after imbalance adjustment):\")\n",
    "    print(submission['next_buy'].value_counts(normalize=True).to_frame('proportion'))\n",
    "generate_submission(test_df, test_preds, y, r'C:\\Users\\rapha\\Documents\\VSCode\\Kaggle\\Intellectra\\Model\\Model')\n",
    "    \n",
    "print(\"\\n--- Workflow Complete ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
